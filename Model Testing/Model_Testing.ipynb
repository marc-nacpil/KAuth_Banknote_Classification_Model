{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6M-22h0VLd9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import random\n",
        "import itertools\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJX2Eiv0f0TC",
        "outputId": "5c32a2a4-d57a-4b65-c13e-aa17221f4450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s0pMa7FXe4i"
      },
      "source": [
        "RESIZES AND CROPS THE IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0vAyaaJVEBj",
        "outputId": "4561d2e7-dd33-4908-8f02-a1a3fc65edd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resizing and cropping completed!\n"
          ]
        }
      ],
      "source": [
        "def resize_and_crop_image(input_path, output_path, roi, target_size):\n",
        "    with Image.open(input_path) as img:\n",
        "        # Resize the image\n",
        "        img_resized = img.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "        # Crop the resized image\n",
        "        x, y, w, h = roi\n",
        "        cropped_img = img_resized.crop((x, y, x+w, y+h))\n",
        "\n",
        "        cropped_img.save(output_path)\n",
        "\n",
        "roi = (465, 633, 516, 559)\n",
        "\n",
        "# ROI 1 = Concealed Value (471, 0, 475, 555)\n",
        "# ROI 2 = OVD (465, 633, 516, 559)\n",
        "\n",
        "# Define the target size for resizing\n",
        "target_size = (3844, 1575)\n",
        "\n",
        "input_directory = \"/content/drive/MyDrive/CS Study 2/Main Model Training/Main Model 6/0_Genuine\"\n",
        "output_directory = \"/content/drive/MyDrive/CS Study 2/Main Model Training/Main Model 6/1_Genuine_OVD\"\n",
        "\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(input_directory):\n",
        "    if filename.endswith((\".JPG\", \".jpg\", \".jpeg\", \".png\")):\n",
        "        input_path = os.path.join(input_directory, filename)\n",
        "        output_path = os.path.join(output_directory, f\"resized_cropped_{filename}\")\n",
        "        resize_and_crop_image(input_path, output_path, roi, target_size)\n",
        "\n",
        "print(\"Resizing and cropping completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG0OA2YuXc8c"
      },
      "source": [
        "PRE PROCESS THE IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFnZfJ4EVrBf",
        "outputId": "42337935-4ab3-407f-9471-4925c12876d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image processing completed!\n",
            "Processed images saved in: /content/drive/MyDrive/CS Study 2/Main Model Training/Main Model 6/2_Genuine_OVD_Pro\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def process_image(input_path, output_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(input_path)\n",
        "    # Resize to 299x299\n",
        "    img_resized = cv2.resize(img, (299, 299))\n",
        "    # Convert to grayscale\n",
        "    img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(img_gray, 100, 200)\n",
        "    # Convert back to RGB (actually BGR for cv2)\n",
        "    img_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
        "    # Save the processed image\n",
        "    cv2.imwrite(output_path, img_rgb)\n",
        "\n",
        "# Directory containing your images\n",
        "input_directory = \"/path/to/dataset/\"\n",
        "# Base directory to save processed images\n",
        "output_base_directory = \"/path/to/dataset/\"\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_base_directory, exist_ok=True)\n",
        "\n",
        "# Process all images\n",
        "for filename in os.listdir(input_directory):\n",
        "    if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "        input_path = os.path.join(input_directory, filename)\n",
        "        output_path = os.path.join(output_base_directory, f\"processed_{filename}\")\n",
        "        process_image(input_path, output_path)\n",
        "\n",
        "print(\"Image processing completed!\")\n",
        "print(f\"Processed images saved in: {output_base_directory}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvOBH8uqXh7S"
      },
      "source": [
        "MODEL TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EazIt4sYVyp_"
      },
      "outputs": [],
      "source": [
        "testing_preprocessed_dataset_path = \"/path/to/dataset/\"\n",
        "\n",
        "# Load the pre-trained model\n",
        "model_path = '/path/to/the/trained/model/'\n",
        "model = load_model(model_path)\n",
        "print(f\"Loading pre-trained model from: {model_path}\")\n",
        "\n",
        "# Define the preprocessing function\n",
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(299, 299))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Normalize the image\n",
        "    return img_array\n",
        "\n",
        "# Create an ImageDataGenerator for the testing set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Get a list of all image files in the testing directory and its subdirectories\n",
        "image_files = []\n",
        "for root, dirs, files in os.walk(testing_preprocessed_dataset_path):\n",
        "    for file in files:\n",
        "        if file.endswith((\".JPG\", \".jpg\", \".jpeg\", \".png\")):\n",
        "            image_files.append(os.path.join(root, file))\n",
        "\n",
        "# Check if any images were found\n",
        "if not image_files:\n",
        "    print(\"No images found in the specified directory.\")\n",
        "else:\n",
        "    print(f\"Found {len(image_files)} images in the testing directory.\")\n",
        "\n",
        "    # List to store prediction probabilities\n",
        "    prediction_probabilities = []\n",
        "\n",
        "    # Make predictions for each image\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    for image_file in image_files:\n",
        "        img_array = preprocess_image(image_file)\n",
        "        prediction_score = model.predict(img_array)[0][0]\n",
        "\n",
        "        # Store the prediction probability\n",
        "        prediction_probabilities.append(prediction_score)\n",
        "\n",
        "        # Classify the image as \"Genuine\" or \"Fake\"\n",
        "        if prediction_score >= 0.8:\n",
        "            prediction = 'Genuine'\n",
        "        else:\n",
        "            prediction = 'Fake'\n",
        "\n",
        "        # Assuming the true label is encoded in the file name\n",
        "        # (e.g., 'genuine_image.jpg' or 'fake_image.jpg')\n",
        "        true_label = 'Genuine' if 'genuine' in os.path.basename(image_file).lower() else 'Fake'\n",
        "\n",
        "        predictions.append(prediction)\n",
        "        true_labels.append(true_label)\n",
        "\n",
        "        # Print the prediction and score\n",
        "        print(f\"{os.path.basename(image_file)}: {prediction} (Score: {prediction_score:.4f})\")\n",
        "\n",
        "    # Convert labels to numerical format for evaluation\n",
        "    label_map = {'Genuine': 1, 'Fake': 0}\n",
        "    true_labels_numeric = [label_map[label] for label in true_labels]\n",
        "    predictions_numeric = [label_map[pred] for pred in predictions]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSzRs48pamdD"
      },
      "source": [
        "MODEL EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "779ntfhOapol"
      },
      "outputs": [],
      "source": [
        "# Plotting the histogram of prediction probabilities\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(prediction_probabilities, bins=20, color='#337FB5', edgecolor='white')\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Predicted Probabilities')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNszoBH9z0qw"
      },
      "outputs": [],
      "source": [
        "# Plotting the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('Actual Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels_numeric, predictions_numeric)\n",
        "plot_confusion_matrix(conf_matrix, classes=['Counterfeit', 'Genuine'], title='Confusion Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8uWGrzMzt0S"
      },
      "outputs": [],
      "source": [
        "# Calculating the accuracy, precision, recall, f1_score\n",
        "\n",
        "# True Positives\n",
        "true_positive = conf_matrix[0, 0]\n",
        "print(f'True Positive: {true_positive}')\n",
        "\n",
        "# True Negatives\n",
        "true_negative = conf_matrix[1, 1]\n",
        "print(f'True Negative: {true_negative}')\n",
        "\n",
        "# False Positives\n",
        "false_positive = conf_matrix[1, 0]\n",
        "print(f'False Positive: {false_positive}')\n",
        "\n",
        "# False Negatives\n",
        "false_negative = conf_matrix[0, 1]\n",
        "print(f'False Negative: {false_negative}')\n",
        "\n",
        "# Accuracy\n",
        "print(\"\\nAccuracy:\")\n",
        "print((true_positive + true_negative) / float(true_positive + true_negative + false_positive + false_negative))\n",
        "print(accuracy_score(true_labels_numeric, predictions_numeric))\n",
        "\n",
        "# Precision\n",
        "print(\"\\nPrecision:\")\n",
        "precision_calculation = true_positive / float(true_positive + false_positive)\n",
        "print(precision_calculation)\n",
        "print(precision_score(true_labels_numeric, predictions_numeric, pos_label=0))\n",
        "\n",
        "# Recall\n",
        "print(\"\\nRecall:\")\n",
        "recall_calculation = true_positive / float(true_positive + false_negative)\n",
        "print(recall_calculation)\n",
        "print(recall_score(true_labels_numeric, predictions_numeric, pos_label=0))\n",
        "\n",
        "# F1 Score\n",
        "print(\"\\nF1 Score:\")\n",
        "f1_score_calculation = 2 * float(precision_calculation * recall_calculation) / float(precision_calculation + recall_calculation)\n",
        "print(f1_score_calculation)\n",
        "print(f1_score(true_labels_numeric, predictions_numeric, pos_label=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfY5HcjOawOZ"
      },
      "outputs": [],
      "source": [
        "# Plotting the accuracy, precision, recall, f1_score\n",
        "\n",
        "# Metrics: accuracy, precision, recall, and F1-score\n",
        "accuracy = accuracy_score(true_labels_numeric, predictions_numeric)\n",
        "precision = precision_score(true_labels_numeric, predictions_numeric, pos_label=0)\n",
        "recall = recall_score(true_labels_numeric, predictions_numeric, pos_label=0)\n",
        "f1 = f1_score(true_labels_numeric, predictions_numeric, pos_label=0)\n",
        "\n",
        "# Metric names and values\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "values = [accuracy * 100, precision * 100, recall * 100, f1 * 100]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(8, 6))\n",
        "bars = plt.bar(metrics, values, color=['#96A493', '#264F78', '#4E8168', '#337FB6'])\n",
        "\n",
        "# Add labels and title\n",
        "plt.ylabel('Percentage (%)')\n",
        "plt.title('Model Evaluation Metrics')\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "# Display the values inside the bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, yval - 10, f'{yval:.2f}%', ha='center', va='center', fontsize=10, color='white')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUeuny9NThYx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "\n",
        "# Define the number of columns in the grid\n",
        "num_cols = 10  # You can adjust this number to change the layout\n",
        "\n",
        "# Calculate the number of rows needed\n",
        "num_rows = math.ceil(len(image_files) / num_cols)\n",
        "\n",
        "# Create a new figure with a size that accommodates the grid\n",
        "plt.figure(figsize=(20, 5 * num_rows))  # Adjust the figure size as needed\n",
        "\n",
        "for idx, (image_file, prediction, prediction_score) in enumerate(zip(image_files, predictions, prediction_probabilities)):\n",
        "    # Create a subplot for each image\n",
        "    plt.subplot(num_rows, num_cols, idx + 1)\n",
        "\n",
        "    # Read and display the image\n",
        "    img = plt.imread(image_file)\n",
        "    plt.imshow(img)\n",
        "\n",
        "    # Set the color based on the condition:\n",
        "    # - Red if \"genuine\" in filename and result is \"Fake\"\n",
        "    # - Red if \"counterfeit\" in filename and result is \"Genuine\"\n",
        "    file_name = os.path.basename(image_file).lower()\n",
        "    if ('genuine' in file_name and prediction == 'Fake') or ('fake' in file_name and prediction == 'Genuine'):\n",
        "        color = 'red'\n",
        "    else:\n",
        "        color = 'green'\n",
        "\n",
        "    # Set the title with filename, prediction, and score\n",
        "    plt.title(f\"{file_name}\\n{prediction}\\n(Score: {prediction_score:.4f})\", color=color, fontsize=8)\n",
        "\n",
        "    # Remove axes\n",
        "    plt.axis('off')\n",
        "\n",
        "# Adjust the layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}