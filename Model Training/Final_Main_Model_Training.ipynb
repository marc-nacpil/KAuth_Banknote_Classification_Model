{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC4iNzMKQyII",
        "outputId": "8415f14b-5157-4b0f-9808-6785b63adcb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import random\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, SpatialDropout2D\n",
        "from keras.applications import Xception\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, BatchNormalization, Conv2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "pL2SQQkVRH6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_dataset(input_directory, output_directory, test_size=0.3):\n",
        "    # Define input directories\n",
        "    genuine_images_dir = os.path.join(input_directory, 'genuine')\n",
        "    fake_images_dir = os.path.join(input_directory, 'fake')\n",
        "\n",
        "    # Function to get all image paths recursively\n",
        "    def get_image_paths(directory):\n",
        "        image_paths = []\n",
        "        for root, _, files in os.walk(directory):\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "                    image_paths.append(os.path.join(root, file))\n",
        "        return image_paths\n",
        "\n",
        "    # Get the paths for genuine and fake images\n",
        "    genuine_image_paths = get_image_paths(genuine_images_dir)\n",
        "    fake_image_paths = get_image_paths(fake_images_dir)\n",
        "\n",
        "    # Combine the genuine and fake image paths\n",
        "    image_paths = genuine_image_paths + fake_image_paths\n",
        "    random.shuffle(image_paths)  # Shuffle the image paths\n",
        "\n",
        "    # Split the dataset into train and validation sets\n",
        "    train_paths, val_paths = train_test_split(image_paths, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Create the train and validation directories\n",
        "    train_genuine_dir = os.path.join(output_directory, 'train', 'genuine')\n",
        "    train_fake_dir = os.path.join(output_directory, 'train', 'fake')\n",
        "    val_genuine_dir = os.path.join(output_directory, 'val', 'genuine')\n",
        "    val_fake_dir = os.path.join(output_directory, 'val', 'fake')\n",
        "    os.makedirs(train_genuine_dir, exist_ok=True)\n",
        "    os.makedirs(train_fake_dir, exist_ok=True)\n",
        "    os.makedirs(val_genuine_dir, exist_ok=True)\n",
        "    os.makedirs(val_fake_dir, exist_ok=True)\n",
        "\n",
        "    # Function to copy images to the appropriate directory\n",
        "    def copy_images(paths, genuine_dir, fake_dir):\n",
        "        for path in paths:\n",
        "            image_name = os.path.basename(path)\n",
        "            if path in genuine_image_paths:\n",
        "                dest_dir = genuine_dir\n",
        "            else:\n",
        "                dest_dir = fake_dir\n",
        "            shutil.copy(path, os.path.join(dest_dir, image_name))\n",
        "\n",
        "    # Save the preprocessed images to the train and validation directories\n",
        "    copy_images(train_paths, train_genuine_dir, train_fake_dir)\n",
        "    copy_images(val_paths, val_genuine_dir, val_fake_dir)\n",
        "\n",
        "    print(f\"Dataset split completed. Train set: {len(train_paths)}, Validation set: {len(val_paths)}\")\n",
        "    return train_paths, val_paths\n",
        "\n",
        "# Example usage\n",
        "input_directory = \"/path/to/dataset/\"\n",
        "output_directory = \"/path/to/dataset/\"\n",
        "test_size = 0.15789473684  # 30% for validation, 70% for training\n",
        "train_paths, val_paths = split_dataset(input_directory, output_directory, test_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z189EjKNRJNi",
        "outputId": "eb8f676f-4fdf-40a6-8c0b-b90ee053b38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split completed. Train set: 1600, Validation set: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch_size = 21\n",
        "val_batch_size = 9"
      ],
      "metadata": {
        "id": "TxyF4r3xRTch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_dataset_path = \"/path/to/dataset/\"\n",
        "\n",
        "# Create data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Path of the generated train folder, and val folder\n",
        "train_data_dir = os.path.join(preprocessed_dataset_path, 'train')\n",
        "val_data_dir = os.path.join(preprocessed_dataset_path, 'val')\n",
        "\n",
        "# Load data from preprocessed directory for training\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(299,299),\n",
        "    batch_size=train_batch_size,\n",
        "    class_mode='binary',\n",
        "    color_mode='rgb',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_data_dir,\n",
        "    target_size=(299,299),\n",
        "    batch_size=val_batch_size,\n",
        "    class_mode='binary',\n",
        "    color_mode='rgb',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Steps per epoch calculation\n",
        "train_samples = train_generator.samples\n",
        "val_samples = validation_generator.samples\n",
        "steps_per_epoch = math.ceil(train_samples / train_batch_size)\n",
        "validation_steps = math.ceil(val_samples / val_batch_size)\n",
        "\n",
        "# Create an infinite generator\n",
        "def recurrent_generator(generator):\n",
        "    while True:\n",
        "        for batch in generator:\n",
        "            yield batch\n",
        "\n",
        "# Wrap the generators\n",
        "train_generator_recurrent = recurrent_generator(train_generator)\n",
        "validation_generator_recurrent = recurrent_generator(validation_generator)"
      ],
      "metadata": {
        "id": "M2QyibGQRLcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base Model"
      ],
      "metadata": {
        "id": "i9Jz5He1Msl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Xception model\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Custom classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Creation of the Model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compiling of the Model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iEVaSFlXRXcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enhanced Model"
      ],
      "metadata": {
        "id": "HJgKhHVXM1tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Custom classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Creation of the model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compiling of the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Define callbacks\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "metadata": {
        "id": "mLkGypU4XkQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator_infinite,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=validation_generator_infinite,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=10,\n",
        ")"
      ],
      "metadata": {
        "id": "vj5uU6oeRbLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Main-Model-3(new3).h5')"
      ],
      "metadata": {
        "id": "ryWFiesLBmJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "train_loss, train_accuracy = model.evaluate(train_generator)       # Evaluate the model's train loss and accuracy"
      ],
      "metadata": {
        "id": "25mGLe1dCz4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train loss: ', train_loss * 100, '%')\n",
        "print('Train accuracy: ', train_accuracy * 100, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9UK_qg0C1dN",
        "outputId": "6e9bb113-0688-4a67-f8a7-278c141cb1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss:  4.344992712140083 %\n",
            "Train accuracy:  100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "validation_loss, validation_accuracy = model.evaluate(validation_generator) # Evaluate the model's validation loss and accuracy"
      ],
      "metadata": {
        "id": "y1I1Wa-CC3mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Validation loss: ', validation_loss * 100, '%')\n",
        "print('Validation accuracy: ', validation_accuracy * 100, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQx6HV3KC403",
        "outputId": "ad24bf6d-8999-47c3-862d-a27a039e415e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss:  4.90671694278717 %\n",
            "Validation accuracy:  100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting training_accuracy and validation_accuracy\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='training set')\n",
        "plt.plot(history.history['val_accuracy'], label='validation set')\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/MyDrive/CS Study 2/Visualizations/ROI_4/Accuracy.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cjbzfQzZRefQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting training_loss and validation_loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy(loss)')\n",
        "plt.plot(history.history['loss'], label='training set')\n",
        "plt.plot(history.history['val_loss'], label='validation set')\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/MyDrive/CS Study 2/Visualizations/ROI_4/Loss.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ZjfRtiHRfKr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}